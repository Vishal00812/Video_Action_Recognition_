# Video_Action_Recognition
This project focuses on recognizing human actions in video sequences. The current model is trained to distinguish between two actions: "Stand Up" and "Sit Down".

## Description

The notebook implements a video action recognition model using deep learning techniques. The model is trained on a dataset consisting of video clips labeled with two classes: "Stand Up" and "Sit Down". The objective is to accurately identify these actions in new video sequences.

## Sample Videos


### Sit down

<<<<<<< HEAD
![](200w.gif)

### Stand up

![](AppropriateDampJumpingbean-small.gif)
=======
![](https://github.com/Vishal00812/Video_Action_Recognition_/assets/104523618/ddbd2dab-b5e2-49de-a66c-8fda5541992c)

### Stand up

![](https://github.com/Vishal00812/Video_Action_Recognition_/assets/104523618/dbf84c18-92e0-4cea-879b-cc387b2923bd)
>>>>>>> 37b00726f155e1c9d6adba8ed3e843468a51018a

## How to use

1. **Data Preparation**: Ensure your video dataset is organized and labeled correctly.
2. **Training**: Run the provided notebook to train the model on your dataset.
3. **Inference**: Use the trained model to classify actions in new video sequences.

## Requirements

- Python
- OpenCV
- TensorFlow
- Other necessary libraries (see requirements.txt)

## Running the Notebook

1. Clone the repository.
2. Install the required libraries.
3. Open the Jupyter notebook and run the cells sequentially.

